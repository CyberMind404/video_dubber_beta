import requests
import time
import re
import unicodedata
from langdetect import detect, DetectorFactory

API_KEY = "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"
DetectorFactory.seed = 0

def clean_arabic_text(text):
    """ุชูุธูู ุงููุต ุงูุนุฑุจู ูู ุงูุฑููุฒ ุงูุบุฑูุจุฉ ูุน ุงูุงุญุชูุงุธ ุจุงูุชุดููู ุงูุตุญูุญ."""
    # ุฅุฒุงูุฉ ุงูุฑููุฒ ุงูุบุฑูุจุฉ ุงูุชู ูุฏ ุชุธูุฑ ุจุณุจุจ ูุดุงูู ุงูุชุฑููุฒ
    unwanted_symbols = ['!', '@', '#', '$', '%', '^', '&', '*', '+', '=', '|', '\\', '/', '<', '>', '?', '`', '~']
    
    for symbol in unwanted_symbols:
        text = text.replace(symbol, '')
    
    # ุฅุฒุงูุฉ ุงููุณุงูุงุช ุงููุชุนุฏุฏุฉ
    text = re.sub(r'\s+', ' ', text)
    
    # ุชูุธูู ุงููุต ูู ุงูุฑููุฒ ุบูุฑ ุงููุฑุบูุจุฉ ูู ุจุฏุงูุฉ ูููุงูุฉ ุงููุต
    text = text.strip()
    
    return text

def split_text_smart(text, max_tokens=1500):
    """ุชูุณูู ุงููุต ุงูุทููู ุฅูู ููุงุทุน ุฐููุฉ ูุน ุงูุญูุงุธ ุนูู ุงูุณูุงู."""
    # ุชูุณูู ุงููุต ุฅูู ุฌูู ุจุงุณุชุฎุฏุงู regex ูุญุณู
    sentences = re.split(r'(?<=[.!?])\s+', text)
    chunks, current = [], ""
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
            
        # ุฅุฐุง ูุงู ุงูุฌููุฉ ุงูุญุงููุฉ + ุงูุฌููุฉ ุงูุฌุฏูุฏุฉ ุฃูู ูู ุงูุญุฏ ุงูุฃูุตู
        if len(current) + len(sentence) < max_tokens:
            current += sentence + " "
        else:
            # ุญูุธ ุงูููุทุน ุงูุญุงูู ุฅุฐุง ูู ููู ูุงุฑุบูุง
            if current.strip():
                chunks.append(current.strip())
            current = sentence + " "
    
    # ุฅุถุงูุฉ ุงูููุทุน ุงูุฃุฎูุฑ ุฅุฐุง ูู ููู ูุงุฑุบูุง
    if current.strip():
        chunks.append(current.strip())
    
    return chunks

def get_language_name(language_code: str) -> str:
    """ุงูุญุตูู ุนูู ุงุณู ุงููุบุฉ ูู ุฑูุฒูุง."""
    language_names = {
        "ar": "ุงูุนุฑุจูุฉ",
        "en": "English",
        "fr": "Franรงais",
        "es": "Espaรฑol",
        "de": "Deutsch",
        "it": "Italiano",
        "pt": "Portuguรชs",
        "ru": "ะัััะบะธะน",
        "zh": "ไธญๆ",
        "ja": "ๆฅๆฌ่ช",
        "ko": "ํ๊ตญ์ด",
        "hi": "เคนเคฟเคจเฅเคฆเฅ",
        "tr": "Tรผrkรงe",
        "nl": "Nederlands",
        "pl": "Polski",
        "sv": "Svenska",
        "da": "Dansk",
        "no": "Norsk",
        "fi": "Suomi",
        "he": "ืขืืจืืช",
        "fa": "ูุงุฑุณ",
        "ur": "ุงุฑุฏู",
        "bn": "เฆฌเฆพเฆเฆฒเฆพ",
        "th": "เนเธเธข",
        "vi": "Tiแบฟng Viแปt",
        "id": "Bahasa Indonesia",
        "ms": "Bahasa Melayu",
        "auto": "ุงูุชุดุงู ุชููุงุฆู"
    }
    return language_names.get(language_code, language_code)

def translate_text_simple(text_en: str) -> str:
    """ุชุฑุฌูุฉ ูุต ุฅูุฌููุฒู ุฅูู ุงูุนุฑุจูุฉ ุจุงุณุชุฎุฏุงู OpenRouter API - ูุณุฎุฉ ูุจุณุทุฉ."""
    return translate_text_general(text_en, "en", "ar")

def translate_text_general(text: str, source_language: str, target_language: str = "ar") -> str:
    """
    ุชุฑุฌูุฉ ูุต ูู ุฃู ูุบุฉ ุฅูู ุฃู ูุบุฉ ุฃุฎุฑู ุจุงุณุชุฎุฏุงู OpenRouter API.
    ูุฌุจ ุชูุฑูุฑ ุงููุบุฉ ุงููุตุฏุฑ ุจุดูู ุตุฑูุญ.
    """
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    # ุชูุณูู ุงููุต ุฅูู ููุงุทุน ุฃุตุบุฑ ุฅุฐุง ูุงู ุทูููุงู
    max_length = 2000
    if len(text) > max_length:
        # ุชูุณูู ุจุณูุท ุนูู ุงูุฌูู
        sentences = re.split(r'(?<=[.!?])\s+', text)
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk) + len(sentence) < max_length:
                current_chunk += sentence + " "
            else:
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + " "
        
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
    else:
        chunks = [text]
    
    final_translation = ""
    
    # ุชุญุฏูุฏ ุฑุณุงูุฉ ุงููุธุงู ุจูุงุกู ุนูู ุงููุบุงุช
    source_lang_name = get_language_name(source_language)
    target_lang_name = get_language_name(target_language)
    
    system_message = f"ุชุฑุฌู ุงููุต ุงูุชุงูู ูู {source_lang_name} ุฅูู {target_lang_name}ุ ูุน ุงูุญูุงุธ ุนูู ุฌููุน ุงููุตุทูุญุงุช ุงูุชูููุฉ ููุง ูู. ุงุฌุนู ุงูุชุฑุฌูุฉ ููุชุถุจุฉ ููุจุงุดุฑุฉ ูุฏุฑ ุงูุฅููุงู ูุชุทุงุจู ุทูู ุงููุต ุงูุฃุตููุ ูุชุฌูุจ ุงูุฅุถุงูุงุช ุบูุฑ ุงูุถุฑูุฑูุฉ."
    
    # ุฅุถุงูุฉ ุชุนูููุงุช ุฎุงุตุฉ ููุนุฑุจูุฉ
    if target_language == "ar":
        system_message += " ุฃุถู ุงูุชุดููู ุงููุงูู (ุงูุญุฑูุงุช) ุฅูู ุฌููุน ุงููููุงุช ุงูุนุฑุจูุฉ ูู ุงูุชุฑุฌูุฉ ูุชุณููู ุงููุฑุงุกุฉ ุงูุขููุฉ."
    
    print(f"๐ ุชุฑุฌูุฉ ุงููุต ูู {source_lang_name} ุฅูู {target_lang_name} ููุณู ุฅูู {len(chunks)} ุฌุฒุก...")
    
    for i, chunk in enumerate(chunks):
        print(f"๐ ุชุฑุฌูุฉ ุงูุฌุฒุก {i + 1} ูู {len(chunks)}...")
        
        data = {
            "model": "deepseek/deepseek-chat-v3-0324:free",
            "messages": [
                {
                    "role": "system",
                    "content": system_message
                },
                {
                    "role": "user",
                    "content": chunk
                }
            ]
        }
        
        try:
            response = requests.post(url, headers=headers, json=data, timeout=30)
            print("RESPONSE STATUS:", response.status_code)
            
            if response.status_code != 200:
                print("RESPONSE TEXT:", response.text)
                raise Exception(f"API returned status {response.status_code}")
                
            translated_chunk = response.json()["choices"][0]["message"]["content"].strip()
            
            # ุชูุธูู ุงููุต ูู ุงูุฑููุฒ ุงูุบุฑูุจุฉ ูุน ุงูุงุญุชูุงุธ ุจุงูุชุดููู ููุนุฑุจูุฉ
            if target_language == "ar":
                translated_chunk = clean_arabic_text(translated_chunk)
            
            # ุฅุถุงูุฉ ุงูุชุฑุฌูุฉ ูุน ูุณุงูุฉ ูุงุญุฏุฉ ููุท
            if final_translation:
                final_translation += " " + translated_chunk
            else:
                final_translation = translated_chunk
                
            # ุงูุชุธุงุฑ ูุตูุฑ ุจูู ุงูุทูุจุงุช ูุชุฌูุจ ุงูุญุธุฑ
            if i < len(chunks) - 1:
                time.sleep(1)
                
        except Exception as e:
            print(f"โ ุฎุทุฃ ุฃุซูุงุก ุชุฑุฌูุฉ ุงูุฌุฒุก {i + 1}: {e}")
            # ุฅุถุงูุฉ ุนูุงูุฉ ููุฌุฒุก ุงููุงุดู
            if final_translation:
                final_translation += f" [ูุดู ูู ุชุฑุฌูุฉ ุงูุฌุฒุก {i + 1}]"
            else:
                final_translation = f"[ูุดู ูู ุชุฑุฌูุฉ ุงูุฌุฒุก {i + 1}]"
    
    return final_translation.strip()

def detect_language_from_text(text: str) -> str:
    """
    ุงูุชุดุงู ูุบุฉ ุงููุต ุจุงุณุชุฎุฏุงู langdetect.
    """
    try:
        lang = detect(text)
        return lang
    except Exception:
        return "unknown"
